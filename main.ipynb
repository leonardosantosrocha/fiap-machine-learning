{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Instala os módulos necessários"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: numpy in /home/leonardo/.local/lib/python3.10/site-packages (1.26.4)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: pandas in /home/leonardo/.local/lib/python3.10/site-packages (2.2.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/leonardo/.local/lib/python3.10/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/leonardo/.local/lib/python3.10/site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: numpy>=1.22.4 in /home/leonardo/.local/lib/python3.10/site-packages (from pandas) (1.26.4)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/lib/python3/dist-packages (from pandas) (2022.1)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: scikit-learn in /home/leonardo/.local/lib/python3.10/site-packages (1.5.2)\n",
      "Requirement already satisfied: scipy>=1.6.0 in /home/leonardo/.local/lib/python3.10/site-packages (from scikit-learn) (1.14.1)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /home/leonardo/.local/lib/python3.10/site-packages (from scikit-learn) (3.5.0)\n",
      "Requirement already satisfied: numpy>=1.19.5 in /home/leonardo/.local/lib/python3.10/site-packages (from scikit-learn) (1.26.4)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /home/leonardo/.local/lib/python3.10/site-packages (from scikit-learn) (1.4.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "\u001b[31mERROR: Could not find a version that satisfies the requirement warnings (from versions: none)\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[31mERROR: No matching distribution found for warnings\u001b[0m\u001b[31m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: xgboost in /home/leonardo/.local/lib/python3.10/site-packages (2.1.1)\n",
      "Requirement already satisfied: nvidia-nccl-cu12 in /home/leonardo/.local/lib/python3.10/site-packages (from xgboost) (2.23.4)\n",
      "Requirement already satisfied: scipy in /home/leonardo/.local/lib/python3.10/site-packages (from xgboost) (1.14.1)\n",
      "Requirement already satisfied: numpy in /home/leonardo/.local/lib/python3.10/site-packages (from xgboost) (1.26.4)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install numpy\n",
    "%pip install pandas\n",
    "%pip install scikit-learn\n",
    "%pip install warnings\n",
    "%pip install xgboost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importa os módulos necessários"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.impute import KNNImputer\n",
    "from xgboost import XGBRegressor\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ignora warnings que serão gerados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Análise exploratória, feature engineering, treinamento e avaliação do modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw = pd.read_csv(r\"_datasets/dataset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>longitude</th>\n",
       "      <th>latitude</th>\n",
       "      <th>housing_median_age</th>\n",
       "      <th>total_rooms</th>\n",
       "      <th>total_bedrooms</th>\n",
       "      <th>population</th>\n",
       "      <th>households</th>\n",
       "      <th>median_income</th>\n",
       "      <th>median_house_value</th>\n",
       "      <th>ocean_proximity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-122.23</td>\n",
       "      <td>37.88</td>\n",
       "      <td>41.0</td>\n",
       "      <td>880.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>322.0</td>\n",
       "      <td>126.0</td>\n",
       "      <td>8.3252</td>\n",
       "      <td>452600.0</td>\n",
       "      <td>NEAR BAY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-122.22</td>\n",
       "      <td>37.86</td>\n",
       "      <td>21.0</td>\n",
       "      <td>7099.0</td>\n",
       "      <td>1106.0</td>\n",
       "      <td>2401.0</td>\n",
       "      <td>1138.0</td>\n",
       "      <td>8.3014</td>\n",
       "      <td>358500.0</td>\n",
       "      <td>NEAR BAY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-122.24</td>\n",
       "      <td>37.85</td>\n",
       "      <td>52.0</td>\n",
       "      <td>1467.0</td>\n",
       "      <td>190.0</td>\n",
       "      <td>496.0</td>\n",
       "      <td>177.0</td>\n",
       "      <td>7.2574</td>\n",
       "      <td>352100.0</td>\n",
       "      <td>NEAR BAY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-122.25</td>\n",
       "      <td>37.85</td>\n",
       "      <td>52.0</td>\n",
       "      <td>1274.0</td>\n",
       "      <td>235.0</td>\n",
       "      <td>558.0</td>\n",
       "      <td>219.0</td>\n",
       "      <td>5.6431</td>\n",
       "      <td>341300.0</td>\n",
       "      <td>NEAR BAY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-122.25</td>\n",
       "      <td>37.85</td>\n",
       "      <td>52.0</td>\n",
       "      <td>1627.0</td>\n",
       "      <td>280.0</td>\n",
       "      <td>565.0</td>\n",
       "      <td>259.0</td>\n",
       "      <td>3.8462</td>\n",
       "      <td>342200.0</td>\n",
       "      <td>NEAR BAY</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   longitude  latitude  housing_median_age  total_rooms  total_bedrooms  \\\n",
       "0    -122.23     37.88                41.0        880.0           129.0   \n",
       "1    -122.22     37.86                21.0       7099.0          1106.0   \n",
       "2    -122.24     37.85                52.0       1467.0           190.0   \n",
       "3    -122.25     37.85                52.0       1274.0           235.0   \n",
       "4    -122.25     37.85                52.0       1627.0           280.0   \n",
       "\n",
       "   population  households  median_income  median_house_value ocean_proximity  \n",
       "0       322.0       126.0         8.3252            452600.0        NEAR BAY  \n",
       "1      2401.0      1138.0         8.3014            358500.0        NEAR BAY  \n",
       "2       496.0       177.0         7.2574            352100.0        NEAR BAY  \n",
       "3       558.0       219.0         5.6431            341300.0        NEAR BAY  \n",
       "4       565.0       259.0         3.8462            342200.0        NEAR BAY  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 20640 entries, 0 to 20639\n",
      "Data columns (total 10 columns):\n",
      " #   Column              Non-Null Count  Dtype  \n",
      "---  ------              --------------  -----  \n",
      " 0   longitude           20640 non-null  float64\n",
      " 1   latitude            20640 non-null  float64\n",
      " 2   housing_median_age  20640 non-null  float64\n",
      " 3   total_rooms         20640 non-null  float64\n",
      " 4   total_bedrooms      20433 non-null  float64\n",
      " 5   population          20640 non-null  float64\n",
      " 6   households          20640 non-null  float64\n",
      " 7   median_income       20640 non-null  float64\n",
      " 8   median_house_value  20640 non-null  float64\n",
      " 9   ocean_proximity     20640 non-null  object \n",
      "dtypes: float64(9), object(1)\n",
      "memory usage: 1.6+ MB\n"
     ]
    }
   ],
   "source": [
    "raw.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A variável \"total_bedrooms\" apresenta 207 nulos, dessa forma, realizaremos a inputação dos dados utilizando a função [KNNImputer](https://scikit-learn.org/stable/modules/generated/sklearn.impute.KNNImputer.html) do SKLearn para preencher os valores ausentes. De modo geral, a função aplica a média (ou outra estatistica de sua preferência) dos \"k\" vizinhos mais próximos do dado faltante e atribui o resultado ele.\n",
    "\n",
    "Entretanto, para isso, precisaremos converter a variável \"ocean_proximity\" para valores numéricos, visto que o KNNImputer não consegue lidar com textos. Para isso, assumiremos que quanto mais próximo o imóvel está em relação ao oceano, maior será o seu valor. Sendo assim, precisaremos descobrir quais são as categorias e a média de valor dos imóveis para cada uma delas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ocean_proximity\n",
       "ISLAND        380440.000000\n",
       "NEAR BAY      259212.311790\n",
       "NEAR OCEAN    249433.977427\n",
       "<1H OCEAN     240084.285464\n",
       "INLAND        124805.392001\n",
       "Name: median_house_value, dtype: float64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw.groupby(by=\"ocean_proximity\")[\"median_house_value\"].mean().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note que a variável \"ocean_proximity\" possui 5 categorias: ISLAND, ou ilha; NEAR BAY, ou próximo ao baia; NEAR OCEAN, ou próximo ao oceano; <1H OCEAN, ou menos de uma hora de distância do oceano; e, INLAND, ou interior. Neste caso, atribuiremos pesos (1.0, 0.8, 0.6, 0.4, 0.2) a cada categoria, priorizando aquelas em que o imóvel está mais próximo do oceano, visto que a nossa hipótese é que imóveis localizados mais próximos do oceano em média são mais valorizados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw[\"ocean_proximity\"] = raw[\"ocean_proximity\"].apply(lambda x: 1.0 if x == \"ISLAND\" else x)\n",
    "raw[\"ocean_proximity\"] = raw[\"ocean_proximity\"].apply(lambda x: 0.8 if x == \"NEAR BAY\" else x)\n",
    "raw[\"ocean_proximity\"] = raw[\"ocean_proximity\"].apply(lambda x: 0.6 if x == \"NEAR OCEAN\" else x)\n",
    "raw[\"ocean_proximity\"] = raw[\"ocean_proximity\"].apply(lambda x: 0.4 if x == \"<1H OCEAN\" else x)\n",
    "raw[\"ocean_proximity\"] = raw[\"ocean_proximity\"].apply(lambda x: 0.2 if x == \"INLAND\" else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ocean_proximity\n",
       "1.0    380440.000000\n",
       "0.8    259212.311790\n",
       "0.6    249433.977427\n",
       "0.4    240084.285464\n",
       "0.2    124805.392001\n",
       "Name: median_house_value, dtype: float64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw.groupby(by=\"ocean_proximity\")[\"median_house_value\"].mean().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neste momento, o conjunto de dados possui apenas dados numéricos, ou seja, podemos aplicar a função KNNImputer para preencher os dados faltantes. Entretanto, precisamos definir qual o melhor valor para \"k\", portanto, iremos criar uma lista com valores de 2 a 5, e em seguida, testar cada um dos conjuntos de dados nos modelos que serão treinados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_values = [2, 3, 4, 5]\n",
    "\n",
    "specs = []\n",
    "\n",
    "for k in k_values:\n",
    "    # Reseta o dataframe \"stage\" para os dados do dataframe \"raw\"\n",
    "    stage = raw.copy()\n",
    "\n",
    "    # Armazena o nome das colunas do dataframe \"stage\" em uma lista\n",
    "    cols_names = list(stage.columns)\n",
    "\n",
    "    # Instancia o KNNImputer com \"k\" vizinhos para imputar os dados faltantes\n",
    "    imputer = KNNImputer(n_neighbors=k)\n",
    "\n",
    "    # Adiciona o dataframe \"spec\" com o resultado KNNImputer e renomeia colunas\n",
    "    specs.append(pd.DataFrame(imputer.fit_transform(stage), columns=cols_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sem dados faltantes, realizaremos o treinamento do [RandomForestRegressor](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html), que de maneira geral, faz o ensamble (ou combinação) de \"n\" árvores de regressão para gerar um modelo final, utilizando a função [GridSearch](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html) do SKLearn, que de modo geral, testa a combinação de \"m\" parâmtros que são definidos em uma lista de parâmetros e, por fim, apresenta o melhor resultado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 864 candidates, totalling 4320 fits\n",
      "Fitting 5 folds for each of 864 candidates, totalling 4320 fits\n",
      "Fitting 5 folds for each of 864 candidates, totalling 4320 fits\n",
      "Fitting 5 folds for each of 864 candidates, totalling 4320 fits\n"
     ]
    }
   ],
   "source": [
    "rf_results = {\n",
    "    \"RMSE\" : [],\n",
    "    \"R2\" : [],\n",
    "    \"PARAMS\" : []\n",
    "}\n",
    "\n",
    "rf_custom_parameters = {\n",
    "    \"n_estimators\" : [10, 25, 50, 100],\n",
    "    \"max_depth\" : [None, 1, 2, 3, 4, 5],\n",
    "    \"min_samples_split\" : [None, 1, 2, 3, 4, 5],\n",
    "    \"min_samples_leaf\" : [None, 1, 2, 3, 4, 5]\n",
    "}\n",
    "\n",
    "for spec in specs:\n",
    "    # Separa as variáveis entre preditoras \"x\" e predita \"y\" e converte para float32\n",
    "    x = spec[[\"longitude\", \"latitude\", \"housing_median_age\", \"total_rooms\", \"total_bedrooms\", \"population\", \"households\", \"median_income\", \"ocean_proximity\"]].astype(\"float32\")\n",
    "    y = spec[\"median_house_value\"].astype(\"float32\")\n",
    "\n",
    "    # Separa os dados entre conjuntos de treino e teste \n",
    "    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3, random_state=42)\n",
    "\n",
    "    # Instancia o RandomForestRegressor com random_state 42\n",
    "    rf = RandomForestRegressor(random_state=42)\n",
    "\n",
    "    # Utiliza o GridSearchCV para estimar os melhores parâmetros utilizados para treinar o modelo\n",
    "    rf_grid_search = GridSearchCV(estimator=rf, param_grid=rf_custom_parameters, cv=5, scoring=\"neg_mean_squared_error\", verbose=True, n_jobs=-1)\n",
    "\n",
    "    # Realiza o treinamento do modelo com dados de treino\n",
    "    rf_grid_search.fit(x_train, y_train)\n",
    "\n",
    "    # Elege o melhor modelo utilizando a função best_estimator_\n",
    "    rf_best_model = rf_grid_search.best_estimator_\n",
    "\n",
    "    # Realiza a predição com base no melhor modelo\n",
    "    rf_y_pred = rf_best_model.predict(x_test)\n",
    "\n",
    "    # Calcula as métricas de erro do modelo RMSE e R2\n",
    "    rmse = np.sqrt(mean_squared_error(y_test, rf_y_pred))\n",
    "    r2 = r2_score(y_test, rf_y_pred)\n",
    "\n",
    "    # Adiciona o resultado do treinamento a lista de resultados\n",
    "    rf_results.get(\"RMSE\").append(round(rmse, 2))\n",
    "    rf_results.get(\"R2\").append(round(r2, 2))\n",
    "    rf_results.get(\"PARAMS\").append(rf_grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================== RESULTADOS ==================================================\n",
      "RMSE: [48549.87, 48503.09, 48525.66, 48540.95]\n",
      "R²: [0.82, 0.82, 0.82, 0.82]\n",
      "PARAMS: [{'max_depth': None, 'min_samples_leaf': 2, 'min_samples_split': 2, 'n_estimators': 100}, {'max_depth': None, 'min_samples_leaf': 2, 'min_samples_split': 2, 'n_estimators': 100}, {'max_depth': None, 'min_samples_leaf': 2, 'min_samples_split': 2, 'n_estimators': 100}, {'max_depth': None, 'min_samples_leaf': 2, 'min_samples_split': 2, 'n_estimators': 100}]\n",
      "================================================================================================================\n",
      "\n",
      "\n",
      "=================================================== VENCEDOR ===================================================\n",
      "RMSE: 48503.09\n",
      "R²: 0.82\n",
      "PARAMS: {'max_depth': None, 'min_samples_leaf': 2, 'min_samples_split': 2, 'n_estimators': 100}\n",
      "================================================================================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"================================================== RESULTADOS ==================================================\")\n",
    "print(f\"RMSE: {rf_results.get('RMSE')}\")\n",
    "print(f\"R²: {rf_results.get('R2')}\")\n",
    "print(f\"PARAMS: {rf_results.get('PARAMS')}\")\n",
    "print(\"================================================================================================================\\n\\n\")\n",
    "\n",
    "print(\"=================================================== VENCEDOR ===================================================\")\n",
    "print(f\"RMSE: {rf_results.get('RMSE')[1]}\")\n",
    "print(f\"R²: {rf_results.get('R2')[1]}\")\n",
    "print(f\"PARAMS: {rf_results.get('PARAMS')[1]}\")\n",
    "print(\"================================================================================================================\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conforme apresentado acima, o melhor valor de \"k\" para realizar a inputação dos dados foi 3, visto que o RMSE (ou Raiz do Erro Quadrático Médio) apresentou o valor mais baixo foi 48503.1, ou seja, o índice 2 da lista de resultados \"rf_results\", cujo k = 3. Sendo assim, realizaremos o treinamento utilizando o [XGBRegressor](https://xgboost.readthedocs.io/en/latest/python/python_api.html#xgboost.XGBRegressor), que de maneira geral, também combina o resultado de árvores de regressão, porém, diferente do [RandomForestRegressor](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html), o XGBRegressor aprende com os erros da última árvore treinada - ou seja, melhora os resultados com base no aprendizado anterior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 3456 candidates, totalling 17280 fits\n",
      "Fitting 5 folds for each of 3456 candidates, totalling 17280 fits\n",
      "Fitting 5 folds for each of 3456 candidates, totalling 17280 fits\n",
      "Fitting 5 folds for each of 3456 candidates, totalling 17280 fits\n"
     ]
    }
   ],
   "source": [
    "xgb_results = {\n",
    "    \"RMSE\" : [],\n",
    "    \"R2\" : [],\n",
    "    \"PARAMS\" : []\n",
    "}\n",
    "\n",
    "xgb_custom_parameters = {\n",
    "    \"n_estimators\" : [10, 25, 50, 100],\n",
    "    \"learning_rate\" : [0.010, 0.025, 0.050, 0.075],\n",
    "    \"max_depth\" : [None, 1, 2, 3, 4, 5],\n",
    "    \"subsample\" : [0.5, 0.6, 0.7, 0.8, 0.9, 1.0],\n",
    "    \"min_child_weight\" : [1, 2, 3, 4, 5, 6]\n",
    "}\n",
    "\n",
    "for spec in specs:\n",
    "    # Separa as variáveis entre preditoras \"x\" e predita \"y\" e converte para float32\n",
    "    x = spec[[\"longitude\", \"latitude\", \"housing_median_age\", \"total_rooms\", \"total_bedrooms\", \"population\", \"households\", \"median_income\", \"ocean_proximity\"]].astype(\"float32\")\n",
    "    y = spec[\"median_house_value\"].astype(\"float32\")\n",
    "\n",
    "    # Separa os dados entre conjuntos de treino e teste \n",
    "    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3, random_state=42)\n",
    "\n",
    "    # Instancia o XGBRegressor com random_state 42\n",
    "    xgb = XGBRegressor(random_state=42)\n",
    "\n",
    "    # Utiliza o GridSearchCV para estimar os melhores parâmetros utilizados para treinar o modelo\n",
    "    xgb_grid_search = GridSearchCV(estimator=xgb, param_grid=xgb_custom_parameters, cv=5, scoring=\"neg_mean_squared_error\", verbose=True, n_jobs=-1)\n",
    "\n",
    "    # Realiza o treinamento do modelo com dados de treino\n",
    "    xgb_grid_search.fit(x_train, y_train)\n",
    "\n",
    "    # Elege o melhor modelo utilizando a função best_estimator_\n",
    "    xgb_best_model = xgb_grid_search.best_estimator_\n",
    "\n",
    "    # Realiza a predição com base no melhor modelo\n",
    "    xgb_y_pred = xgb_best_model.predict(x_test)\n",
    "\n",
    "    # Calcula as métricas de erro do modelo RMSE e R2\n",
    "    rmse = np.sqrt(mean_squared_error(y_test, xgb_y_pred))\n",
    "    r2 = r2_score(y_test, xgb_y_pred)\n",
    "\n",
    "    # Adiciona o resultado do treinamento a lista de resultados\n",
    "    xgb_results.get(\"RMSE\").append(round(rmse, 2))\n",
    "    xgb_results.get(\"R2\").append(round(r2, 2))\n",
    "    xgb_results.get(\"PARAMS\").append(xgb_grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================== RESULTADOS ==================================================\n",
      "RMSE: [48729.55, 48680.74, 48695.63, 48696.06]\n",
      "R²: [0.82, 0.82, 0.82, 0.82]\n",
      "PARAMS: [{'learning_rate': 0.075, 'max_depth': None, 'min_child_weight': 2, 'n_estimators': 100, 'subsample': 0.9}, {'learning_rate': 0.075, 'max_depth': None, 'min_child_weight': 2, 'n_estimators': 100, 'subsample': 0.9}, {'learning_rate': 0.075, 'max_depth': None, 'min_child_weight': 2, 'n_estimators': 100, 'subsample': 0.9}, {'learning_rate': 0.075, 'max_depth': None, 'min_child_weight': 2, 'n_estimators': 100, 'subsample': 0.9}]\n",
      "================================================================================================================\n",
      "\n",
      "\n",
      "=================================================== VENCEDOR ===================================================\n",
      "RMSE: 48680.73828125\n",
      "R²: 0.82\n",
      "PARAMS: {'learning_rate': 0.075, 'max_depth': None, 'min_child_weight': 2, 'n_estimators': 100, 'subsample': 0.9}\n",
      "================================================================================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"================================================== RESULTADOS ==================================================\")\n",
    "print(f\"RMSE: {xgb_results.get('RMSE')}\")\n",
    "print(f\"R²: {xgb_results.get('R2')}\")\n",
    "print(f\"PARAMS: {xgb_results.get('PARAMS')}\")\n",
    "print(\"================================================================================================================\\n\\n\")\n",
    "\n",
    "print(\"=================================================== VENCEDOR ===================================================\")\n",
    "print(f\"RMSE: {xgb_results.get('RMSE')[1]}\")\n",
    "print(f\"R²: {xgb_results.get('R2')[1]}\")\n",
    "print(f\"PARAMS: {xgb_results.get('PARAMS')[1]}\")\n",
    "print(\"================================================================================================================\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
